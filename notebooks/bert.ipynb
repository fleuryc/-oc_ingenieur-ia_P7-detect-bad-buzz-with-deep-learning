{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 05:07:57.791386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-21 05:07:57.791409: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Downloading and extracting data files...\n",
      "Data files already downloaded.\n",
      ">>> OK.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom helper libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import data.helpers as data_helpers\n",
    "import visualization.helpers as viz_helpers\n",
    "\n",
    "# Maths modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Viz modules\n",
    "import plotly.express as px\n",
    "\n",
    "# Render for export\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Download and unzip CSV files\n",
    "!cd .. && make dataset && cd notebooks\n",
    "# Load data from CSV\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"..\", \"data\", \"raw\", \"training.1600000.processed.noemoticon.csv\"\n",
    "    ),\n",
    "    names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"],\n",
    ")\n",
    "\n",
    "# Reduce memory usage\n",
    "df = data_helpers.reduce_dataframe_memory_usage(df)\n",
    "\n",
    "# Drop useless columns\n",
    "df.drop(columns=[\"id\", \"date\", \"flag\", \"user\"], inplace=True)\n",
    "\n",
    "# Replace target values with labels\n",
    "df.target.replace(\n",
    "    {\n",
    "        0: \"NEGATIVE\",\n",
    "        2: \"NEUTRAL\",\n",
    "        4: \"POSITIVE\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df = data_helpers.balance_sample(df, \"target\", 1*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " #0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\u001b[A\n",
      "\n",
      " #0: 100%|██████████| 1/1 [00:00<00:00, 14.96ba/s]\n",
      " #2: 100%|██████████| 1/1 [00:00<00:00, 16.94ba/s]\n",
      " #1: 100%|██████████| 1/1 [00:00<00:00, 11.87ba/s]\n",
      " #3: 100%|██████████| 1/1 [00:00<00:00, 12.71ba/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 6787.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "# Tokenizers, Stemmers and Lemmatizers\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer_columns = tokenizer.model_input_names\n",
    "label_column = \"target\"\n",
    "\n",
    "\n",
    "# Processed data path\n",
    "processed_data_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "tokenized_dataset_file_path = os.path.join(\n",
    "    processed_data_path, \"bert_tokenized_as_dataframe_dataset.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "# if os.path.exists(tokenized_dataset_file_path):\n",
    "#     # Load encoded dataset\n",
    "#     with (open(tokenized_dataset_file_path, \"rb\")) as f:\n",
    "#         X = pickle.load(f)\n",
    "# else:\n",
    "## Encode text\n",
    "dataset_df = Dataset.from_pandas(df).map(\n",
    "    lambda data: tokenizer(\n",
    "        data[\"text\"], padding=\"max_length\", truncation=True\n",
    "    ),\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    ").to_pandas()\n",
    "\n",
    "X = [np.array([dataset_df.iloc[x][col] for col in tokenizer_columns]).ravel() for x in tqdm(range(len(dataset_df)))]\n",
    "\n",
    "    # # Save vectorized dataset as pickle\n",
    "    # with open(tokenized_dataset_file_path, \"wb\") as f:\n",
    "    #     pickle.dump(X, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    df.target,\n",
    "    test_size=0.2,\n",
    "    stratify=df.target,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Fitting model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 898, in train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 460, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 73, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/metrics.py\", line 177, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/metrics.py\", line 2343, in update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 625, in update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8286/3407197373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# fit NN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p7/env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 898, in train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 460, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 73, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/metrics.py\", line 177, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/metrics.py\", line 2343, in update_state  **\n        return metrics_utils.update_confusion_matrix_variables(\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 625, in update_confusion_matrix_variables\n        y_pred.shape.assert_is_compatible_with(y_true.shape)\n\n    ValueError: Shapes (None, 2) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.metrics import AUC\n",
    "\n",
    "\n",
    "# Model constants.\n",
    "model_name = \"bert_for_sequence_classification_on_bert_tokenized_text\"\n",
    "\n",
    "results_data_path = os.path.join(\"..\", \"results\")\n",
    "model_file_path = os.path.join(results_data_path, model_name)\n",
    "\n",
    "if os.path.exists(model_file_path):\n",
    "    # Load model\n",
    "    model = load_model(model_file_path)\n",
    "else:\n",
    "    # Define NN model\n",
    "    print(\"Defining model...\")\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "    # compile NN network\n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            AUC(curve=\"ROC\", name=\"ROC_AUC\"),\n",
    "            AUC(curve=\"PR\", name=\"AP\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # fit NN model\n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(\n",
    "        np.array(X_train),\n",
    "        y_train,\n",
    "        # validation_split=0.2,\n",
    "        epochs=10,\n",
    "        batch_size=128,\n",
    "        callbacks=[\n",
    "            TensorBoard(log_dir=f\"logs/{model.name}\"),\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "        ],\n",
    "        workers=4,\n",
    "        use_multiprocessing=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    print(\"Saving model...\")\n",
    "    model.save(model_file_path)\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    StagingError: Exception encountered when calling layer \"tf_bert_for_sequence_classification_1\" (type TFBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1727, in call  *\n            inputs = input_processing(\n        File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 420, in input_processing  *\n            output[parameter_names[i]] = input\n    \n        IndexError: list index out of range\n    \n    \n    Call arguments received:\n      • input_ids=('tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)')\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=False\n      • kwargs=<class 'inspect._empty'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8286/1201917382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/oc_p7/env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    StagingError: Exception encountered when calling layer \"tf_bert_for_sequence_classification_1\" (type TFBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1727, in call  *\n            inputs = input_processing(\n        File \"/home/clement/Workspace/oc_p7/env/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 420, in input_processing  *\n            output[parameter_names[i]] = input\n    \n        IndexError: list index out of range\n    \n    \n    Call arguments received:\n      • input_ids=('tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)', 'tf.Tensor(shape=(32,), dtype=int32)')\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=False\n      • kwargs=<class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "model.predict(\n",
    "    input_ids=np.array(X_test)[0:512],\n",
    "    attention_mask=np.array(X_test)[:, :-1],\n",
    "\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "985dab4142e640f9d316b4a6ee5dfcc3b3a4782860c49b4d63e46ae9dfb02f20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
