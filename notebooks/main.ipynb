{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Paradis : Detect bad buzz with deep learning\n",
    "\n",
    "## Context\n",
    "\n",
    "\"Air Paradis\" is an airline company who's marketing department wants to be able to detect quickly \"bad buzz\" on social networks, to be able to anticipate and address issues as fast as possible. They need an AI API that can detect \"bad buzz\" and predict the reason for it.\n",
    "\n",
    "The goal here is to evaluate different approaches to detect \"bad buzz\" :\n",
    "\n",
    "1. [Baseline Model : Logistic Regression](1_baseline.ipynb)\n",
    "2. [Word embedding : Gensim Doc2Vec](2_word_embedding.ipynb)\n",
    "3. [Azure Cognitive Services : Text Analytics API](3_azure_sentiment_analysis.ipynb)\n",
    "4. [HuggingFace Transformer Pipeline : Sentiment Analysis](4_huggingface_sentiment_analysis.ipynb)\n",
    "5. [HuggingFace : BERT Fine-tuning](5_huggingface_bert_fine_tuning.ipynb)\n",
    "6. [AzureML Studio : Automated ML](6_azureml_automated_ml.ipynb)\n",
    "7. [AzureML Studio : Designer](7_azureml_designer.ipynb)\n",
    "8. [Custom Models : Neural Networks with Keras](8_keras_neural_networks.ipynb)\n",
    "9. [AzureML Studio : Notebooks](9_azureml_notebooks.ipynb)\n",
    "\n",
    "After exploring our dataset, we will compare the different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project modules\n",
    "\n",
    "The helpers functions and project specific code will be placed in `../src/`.\n",
    "\n",
    "We will use the [Python](https://www.python.org/about/gettingstarted/) programming language, and present here the code and results in this [Notebook JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html) file.\n",
    "\n",
    "We will use the usual libraries for data exploration, modeling and visualisation :\n",
    "\n",
    "- [NumPy](https://numpy.org/doc/stable/user/quickstart.html) and [Pandas](https://pandas.pydata.org/docs/user_guide/index.html) : for maths (stats, algebra, ...) and large data manipulation\n",
    "- [Plotly](https://plotly.com/python/getting-started/) : for interactive data visualization\n",
    "\n",
    "We will also use libraries specific to the goals of this project :\n",
    "\n",
    "- NLP Natural Language Processing\n",
    "  - [NLTK](https://www.nltk.org/) and [Spacy](https://spacy.io/api) : for text processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Import custom helper libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import data.helpers as data_helpers\n",
    "import visualization.helpers as viz_helpers\n",
    "\n",
    "# Maths modules\n",
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "\n",
    "# Viz modules\n",
    "import plotly.express as px\n",
    "\n",
    "# Render for export\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)\n",
    "\n",
    "We are going to load the data and analyse the distribution of each variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Let's download the data from the [Kaggle - Sentiment140 dataset with 1.6 million tweets](https://www.kaggle.com/kazanova/sentiment140) competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip CSV files\n",
    "!cd .. && make dataset && cd notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\"..\", \"data\", \"raw\", \"training.1600000.processed.noemoticon.csv\"),\n",
    "    names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"],\n",
    ")\n",
    "\n",
    "# Reduce memory usage\n",
    "df = data_helpers.reduce_dataframe_memory_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data\n",
    "\n",
    "Let's display a few examples, find out how many data points are available, what are the variables and what is their distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diaplay number of rows and colmn types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are _1600000_ rows, each composed of _6_ columns :\n",
    "\n",
    "- _target_: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "- _id_: The id of the tweet ( 2087)\n",
    "- _date_: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "- _flag_: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "- _user_: the user that tweeted (robotickilldozr)\n",
    "- _text_: the text of the tweet (Lyx is cool)\n",
    "\n",
    "We are only interrested in the _target_ and _text_ variables. The rest of the columns are not useful for our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df.drop(columns=[\"id\", \"date\", \"flag\", \"user\"], inplace=True)\n",
    "\n",
    "# Replace target values with labels\n",
    "df.target = df.target.map(\n",
    "    {\n",
    "        0: \"NEGATIVE\",\n",
    "        2: \"NEUTRAL\",\n",
    "        4: \"POSITIVE\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target distribution\n",
    "viz_helpers.histogram(\n",
    "    df, label_x=\"target\", label_colour=\"target\", title=\"Target distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are exactly as many (800000) _POSITIVE_ tweets as _NEGATIVE_ tweets. There are no _NEUTRAL_ tweets.\n",
    "The problem is well balanced and there will be no bias towards one class during the training of our models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot text length distribution\n",
    "df[\"text_length\"] = df.text.str.len()\n",
    "\n",
    "p_value = f_oneway(\n",
    "    df.loc[df[\"target\"] == \"NEGATIVE\", \"text_length\"],\n",
    "    df.loc[df[\"target\"] == \"POSITIVE\", \"text_length\"],\n",
    ")[1]\n",
    "\n",
    "viz_helpers.histogram(\n",
    "    df,\n",
    "    label_x=\"text_length\",\n",
    "    label_colour=\"target\",\n",
    "    title=f\"Text length distribution / p-value={p_value:.5f}\",\n",
    "    include_boxplot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no big difference between the _POSITIVE_ and _NEGATIVE_ tweets, but _NEGATIVE_ tweets are slightly longer than _POSITIVE_ tweets.\n",
    "In both classes, there are two modes : _~45_ characters and _138_ characters (the maximum allowed at some point).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot word count distribution\n",
    "df[\"word_count\"] = df.text.str.split().str.len()\n",
    "\n",
    "p_value = f_oneway(\n",
    "    df.loc[df[\"target\"] == \"NEGATIVE\", \"word_count\"],\n",
    "    df.loc[df[\"target\"] == \"POSITIVE\", \"word_count\"],\n",
    ")[1]\n",
    "\n",
    "viz_helpers.histogram(\n",
    "    df,\n",
    "    label_x=\"word_count\",\n",
    "    label_colour=\"target\",\n",
    "    title=f\"Word count distribution / p-value={p_value:.5f}\",\n",
    "    include_boxplot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no big difference between the _POSITIVE_ and _NEGATIVE_ tweets, but _NEGATIVE_ tweets are significatively longer than _POSITIVE_ tweets.\n",
    "In both classes, there are two modes : _~7_ words and _~20_ words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text analysis\n",
    "\n",
    "We will look more in details at what contains the _text_ variable.\n",
    "\n",
    "First, we will transform the dataset into a Bag of Words representation with TfIdf (Term Frequency - Inverse Document Frequency) weights.\n",
    "To achieve this, we are going to use th SpaCy tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tokenizers, Stemmers and Lemmatizers\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Download resources\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Download SpaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define tokenizer\n",
    "tokenizer = lambda text: [  # SpaCy Lemmatizer\n",
    "    token.lemma_.lower() for token in nlp(text) if token.is_alpha and not token.is_stop\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed data path\n",
    "processed_data_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "vectorized_dataset_file_path = os.path.join(\n",
    "    processed_data_path, \"tfidf_spacy_dataset.pkl\"\n",
    ")\n",
    "vocabulary_file_path = os.path.join(processed_data_path, \"tfidf_spacy_vocabulary.pkl\")\n",
    "\n",
    "if os.path.exists(vectorized_dataset_file_path) and os.path.exists(\n",
    "    vocabulary_file_path\n",
    "):\n",
    "    # Load vectorized dataset\n",
    "    with (open(vectorized_dataset_file_path, \"rb\")) as f:\n",
    "        X = pickle.load(f)\n",
    "    # Load vocabulary\n",
    "    with (open(vocabulary_file_path, \"rb\")) as f:\n",
    "        vocabulary = pickle.load(f)\n",
    "else:\n",
    "    # Define vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        strip_accents=\"unicode\",\n",
    "        lowercase=True,\n",
    "        stop_words=stopwords,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # Vectorize text\n",
    "    X = vectorizer.fit_transform(df.text)\n",
    "\n",
    "    # Get vocabulary\n",
    "    vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Save vectorized dataset as pickle\n",
    "    with open(vectorized_dataset_file_path, \"wb\") as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "    # Save vocabulary as pickle\n",
    "    with open(vocabulary_file_path, \"wb\") as f:\n",
    "        pickle.dump(vocabulary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpus is now transformed into a BoW representation. We can analyse the words frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List words TF-IDF scores\n",
    "words = pd.Series(X.sum(axis=0).A1, index=vocabulary)\n",
    "\n",
    "# Top 20 tokens by TfIdf\n",
    "top_20_words = words.nlargest(20).sort_values(ascending=False)\n",
    "\n",
    "# Plot top 20 tokens by TfIdf\n",
    "fig = px.bar(\n",
    "    top_20_words,\n",
    "    x=top_20_words.index,\n",
    "    y=top_20_words.values,\n",
    "    labels={\"x\": \"Words\", \"y\": \"Count\", \"color\": \"Count\"},\n",
    "    title=f\"Top 20 important words (Tf-Idf) - Vocalbulary size: {len(vocabulary)}\",\n",
    "    color=top_20_words.values,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most important words actually meaningful and relevant regarding the sentiment associated to each message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 - Logistic Regression</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>108688</td>\n",
       "      <td>107510</td>\n",
       "      <td>52490</td>\n",
       "      <td>51312</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.675619</td>\n",
       "      <td>0.674335</td>\n",
       "      <td>0.679300</td>\n",
       "      <td>0.679300</td>\n",
       "      <td>0.671937</td>\n",
       "      <td>0.676808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 - Word embedding</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>119134</td>\n",
       "      <td>105070</td>\n",
       "      <td>54930</td>\n",
       "      <td>40866</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.700638</td>\n",
       "      <td>0.684426</td>\n",
       "      <td>0.744587</td>\n",
       "      <td>0.744587</td>\n",
       "      <td>0.656687</td>\n",
       "      <td>0.713241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1 - Azure Cognitive Service API</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>788</td>\n",
       "      <td>673</td>\n",
       "      <td>327</td>\n",
       "      <td>212</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>0.706726</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.745154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2 - Logistic Regression on Azure Cognitive S...</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>164</td>\n",
       "      <td>123</td>\n",
       "      <td>77</td>\n",
       "      <td>36</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.680498</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.743764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 - HuggingFace Sentiment Analysis</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>622</td>\n",
       "      <td>798</td>\n",
       "      <td>202</td>\n",
       "      <td>378</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.754854</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.682018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 - HuggingFace BERT Fine-tuning</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>99585</td>\n",
       "      <td>17631</td>\n",
       "      <td>82369</td>\n",
       "      <td>415</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.586080</td>\n",
       "      <td>0.547309</td>\n",
       "      <td>0.995850</td>\n",
       "      <td>0.995850</td>\n",
       "      <td>0.176310</td>\n",
       "      <td>0.706392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Sampling  \\\n",
       "0                            1 - Logistic Regression   1.00000   \n",
       "1                                 2 - Word embedding   1.00000   \n",
       "2                  3.1 - Azure Cognitive Service API   1.00000   \n",
       "3  3.2 - Logistic Regression on Azure Cognitive S...   0.00125   \n",
       "4                 4 - HuggingFace Sentiment Analysis   1.00000   \n",
       "5                   5 - HuggingFace BERT Fine-tuning   1.00000   \n",
       "\n",
       "   True Positives  True Negatives  False Positives  False Negatives  \\\n",
       "0          108688          107510            52490            51312   \n",
       "1          119134          105070            54930            40866   \n",
       "2             788             673              327              212   \n",
       "3             164             123               77               36   \n",
       "4             622             798              202              378   \n",
       "5           99585           17631            82369              415   \n",
       "\n",
       "   Average Precision  ROC AUC  Accuracy  Precision    Recall  Sensitivity  \\\n",
       "0              0.730    0.740  0.675619   0.674335  0.679300     0.679300   \n",
       "1              0.750    0.770  0.700638   0.684426  0.744587     0.744587   \n",
       "2              0.750    0.780  0.730500   0.706726  0.788000     0.788000   \n",
       "3              0.760    0.780  0.717500   0.680498  0.820000     0.820000   \n",
       "4              0.790    0.800  0.710000   0.754854  0.622000     0.622000   \n",
       "5              0.822    0.883  0.586080   0.547309  0.995850     0.995850   \n",
       "\n",
       "   Specificity        F1  \n",
       "0     0.671937  0.676808  \n",
       "1     0.656687  0.713241  \n",
       "2     0.673000  0.745154  \n",
       "3     0.615000  0.743764  \n",
       "4     0.798000  0.682018  \n",
       "5     0.176310  0.706392  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results_df = pd.DataFrame(\n",
    "    data=[\n",
    "        {\n",
    "            \"Model\": \"1 - Logistic Regression\",\n",
    "            \"Sampling\": 1,\n",
    "            \"True Positives\": 108688,\n",
    "            \"True Negatives\": 107510,\n",
    "            \"False Positives\": 52490,\n",
    "            \"False Negatives\": 51312,\n",
    "            \"Average Precision\": 0.73,\n",
    "            \"ROC AUC\": 0.74,\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"2 - Word embedding\",\n",
    "            \"Sampling\": 1,\n",
    "            \"True Positives\": 119134,\n",
    "            \"True Negatives\": 105070,\n",
    "            \"False Positives\": 54930,\n",
    "            \"False Negatives\": 40866,\n",
    "            \"Average Precision\": 0.75,\n",
    "            \"ROC AUC\": 0.77,\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"3.1 - Azure Cognitive Service API\",\n",
    "            \"Sampling\": 1,\n",
    "            \"True Positives\": 788,\n",
    "            \"True Negatives\": 673,\n",
    "            \"False Positives\": 327,\n",
    "            \"False Negatives\": 212,\n",
    "            \"Average Precision\": 0.75,\n",
    "            \"ROC AUC\": 0.78,\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"3.2 - Logistic Regression on Azure Cognitive Service\",\n",
    "            \"Sampling\": 2000 / 1600000,\n",
    "            \"True Positives\": 164,\n",
    "            \"True Negatives\": 123,\n",
    "            \"False Positives\": 77,\n",
    "            \"False Negatives\": 36,\n",
    "            \"Average Precision\": 0.76,\n",
    "            \"ROC AUC\": 0.78,\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"4 - HuggingFace Sentiment Analysis\",\n",
    "            \"Sampling\": 1,\n",
    "            \"True Positives\": 622,\n",
    "            \"True Negatives\": 798,\n",
    "            \"False Positives\": 202,\n",
    "            \"False Negatives\": 378,\n",
    "            \"Average Precision\": 0.79,\n",
    "            \"ROC AUC\": 0.80,\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"5 - HuggingFace BERT Fine-tuning\",\n",
    "            \"Sampling\": 1,\n",
    "            \"True Positives\": 99585,\n",
    "            \"True Negatives\": 17631,\n",
    "            \"False Positives\": 82369,\n",
    "            \"False Negatives\": 415,\n",
    "            \"Average Precision\": 0.822,\n",
    "            \"ROC AUC\": 0.883,\n",
    "        },\n",
    "        {\n",
    "            \"Model\": \"6 - AzureML Studio : Automated ML\",\n",
    "            \"Sampling\": 1,\n",
    "            \"True Positives\": 99585,\n",
    "            \"True Negatives\": 17631,\n",
    "            \"False Positives\": 82369,\n",
    "            \"False Negatives\": 415,\n",
    "            \"Average Precision\": 0.822,\n",
    "            \"ROC AUC\": 0.883,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "models_results_df[\"Accuracy\"] = (\n",
    "    models_results_df[\"True Positives\"] + models_results_df[\"True Negatives\"]\n",
    ") / (\n",
    "    models_results_df[\"True Positives\"]\n",
    "    + models_results_df[\"True Negatives\"]\n",
    "    + models_results_df[\"False Positives\"]\n",
    "    + models_results_df[\"False Negatives\"]\n",
    ")\n",
    "\n",
    "models_results_df[\"Precision\"] = models_results_df[\"True Positives\"] / (\n",
    "    models_results_df[\"True Positives\"] + models_results_df[\"False Positives\"]\n",
    ")\n",
    "\n",
    "models_results_df[\"Recall\"] = models_results_df[\"True Positives\"] / (\n",
    "    models_results_df[\"True Positives\"] + models_results_df[\"False Negatives\"]\n",
    ")\n",
    "\n",
    "models_results_df[\"Sensitivity\"] = models_results_df[\"True Positives\"] / (\n",
    "    models_results_df[\"True Positives\"] + models_results_df[\"False Negatives\"]\n",
    ")\n",
    "\n",
    "models_results_df[\"Specificity\"] = models_results_df[\"True Negatives\"] / (\n",
    "    models_results_df[\"True Negatives\"] + models_results_df[\"False Positives\"]\n",
    ")\n",
    "\n",
    "models_results_df[\"F1\"] = (\n",
    "    2\n",
    "    * models_results_df[\"True Positives\"]\n",
    "    / (\n",
    "        2 * models_results_df[\"True Positives\"]\n",
    "        + models_results_df[\"False Positives\"]\n",
    "        + models_results_df[\"False Negatives\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "models_results_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "985dab4142e640f9d316b4a6ee5dfcc3b3a4782860c49b4d63e46ae9dfb02f20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
